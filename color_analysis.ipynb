{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4701 Project: Personal Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(F\"Device set to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ColorSeasonDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorSeasonDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None, indices=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory containing the RGB-M folder\n",
    "            split (string): 'train' or 'test'\n",
    "            transform (callable, optional): Transform to apply to images\n",
    "            indices (list, optional): If provided, only use these indices\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        \n",
    "        # Define season and subtype mapping\n",
    "        self.seasons = ['spring', 'summer', 'autumn', 'winter']\n",
    "        self.subtypes = {\n",
    "            'spring': ['warm', 'light', 'bright'],\n",
    "            'summer': ['cool', 'light', 'soft'],\n",
    "            'autumn': ['warm', 'deep', 'soft'],\n",
    "            'winter': ['cool', 'deep', 'bright']\n",
    "        }\n",
    "        \n",
    "        # Collect all image paths and corresponding labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        base_path = os.path.join(root_dir, 'RGB-M', split)\n",
    "        \n",
    "        for season_idx, season in enumerate(self.seasons):\n",
    "            season_path = os.path.join(base_path, season)\n",
    "            if not os.path.isdir(season_path):\n",
    "                continue\n",
    "                \n",
    "            for subtype_idx, subtype in enumerate(self.subtypes[season]):\n",
    "                subtype_path = os.path.join(season_path, subtype)\n",
    "                if not os.path.isdir(subtype_path):\n",
    "                    continue\n",
    "                    \n",
    "                for img_file in os.listdir(subtype_path):\n",
    "                    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(season_path, subtype, img_file))\n",
    "                        \n",
    "                        # Calculate combined label (0-11 for 4 seasons Ã— 3 subtypes)\n",
    "                        combined_label = season_idx * 3 + subtype_idx\n",
    "                        self.labels.append(combined_label)\n",
    "        \n",
    "        # If indices are provided, use only those\n",
    "        if indices is not None:\n",
    "            self.image_paths = [self.image_paths[i] for i in indices]\n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define transforms to data and create train/test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note here**: \n",
    "- The authors split the data into 4000 images for training and 900 images for testing (80-20 split)\n",
    "- It's good practice to have validation set but I'm skipping it for now because I'll use stratified k-fold cross validation later\n",
    "- This is because the dataset is small so I don't want to lose more data by splitting test set it into validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data\n",
    "PATH_TO_DATA = 'TODO: path to data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random transforms for training time\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandAugment(2, 7), # not sure about this because I don't want colors changing for color classification\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define fixed transforms for test time\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the joint loss model classifier\n",
    "%load_ext autoreload\n",
    "%aimport joint_model_loss\n",
    "%autoreload 1\n",
    "from models.joint_loss_model import ColorSeasonClassifier, kfold_crossval\n",
    "from loss_functions import joint_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ColorSeasonDataset(\n",
    "    root_dir=PATH_TO_DATA,\n",
    "    split='train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = ColorSeasonDataset(\n",
    "    root_dir=PATH_TO_DATA,\n",
    "    split='test',\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "model_class = ColorSeasonClassifier()\n",
    "criterion = joint_loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few parameter configurations to try\n",
    "param_configs = [\n",
    "    {\n",
    "        'name': 'Default Config',\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'alpha': 0.4,\n",
    "        'beta': 0.4,\n",
    "        'gamma': 0.2,\n",
    "        'num_epochs': 10,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    # {\n",
    "    #     'name': 'Higher LR Config',\n",
    "    #     'learning_rate': 3e-4,\n",
    "    #     'weight_decay': 1e-4,\n",
    "    #     'alpha': 0.4,\n",
    "    #     'beta': 0.4,\n",
    "    #     'gamma': 0.2,\n",
    "    #     'num_epochs': 10,\n",
    "    #     'batch_size': 32\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'Season Focus Config',\n",
    "    #     'learning_rate': 1e-4,\n",
    "    #     'weight_decay': 1e-4,\n",
    "    #     'alpha': 0.6,  # More weight on season\n",
    "    #     'beta': 0.2,\n",
    "    #     'gamma': 0.2,\n",
    "    #     'num_epochs': 10,\n",
    "    #     'batch_size': 32\n",
    "    # }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Evaluate each configuration using k-fold CV\n",
    "results = []\n",
    "for config in param_configs:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = kfold_crossval(\n",
    "        params=config,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=train_dataset,\n",
    "        model_class=model_class,\n",
    "        criterion=criterion,\n",
    "        test_transform=test_transform,\n",
    "        device=device,\n",
    "        n_splits=5\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Evaluation took {elapsed_time:.1f} seconds\")\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "# Find the best configuration\n",
    "best_result = max(results, key=lambda x: x['avg_best_val_acc'])\n",
    "best_config = best_result['params']\n",
    "\n",
    "print(f\"\\nBest configuration: {best_config['name']}\")\n",
    "print(f\"Average validation accuracy: {best_result['avg_best_val_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 (in progress): Fine Tune EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm # For progress bar during training\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mount your Google Drive; this allows the runtime environment to access your drive.\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# NOTE: Make sure your path does NOT include a '/' at the end!\n",
    "base_dir = \"/content/gdrive/MyDrive/AI-PRAC\"\n",
    "sys.path.append(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/content/gdrive/MyDrive/AI-PRAC/dataset/train'\n",
    "val_dir = '/content/gdrive/MyDrive/AI-PRAC/dataset/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(F\"Device set to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random transforms for training time\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandAugment(2, 7), # not sure about this because I don't want colors changing for color classification\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform = train_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform = train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# Modify the final layer for 4 classes (for your classification task)\n",
    "model._fc = nn.Linear(model._fc.in_features, 4)\n",
    "model.to(device)\n",
    "\n",
    "#loss function and optimizer is cross entropy and Adam for now\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct_preds = 0\n",
    "  total_preds = 0\n",
    "  for inputs, labels in tqdm(train_loader):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    total_preds += labels.size(0)\n",
    "\n",
    "    correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "  avg_train_loss = running_loss / len(train_loader)\n",
    "  train_losses.append(avg_train_loss)\n",
    "  train_accuracy = correct_preds / total_preds\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  print(f\"Train Loss: {avg_train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "  #Validation phase\n",
    "  model.eval()\n",
    "  val_running_loss = 0.0\n",
    "  val_correct_preds = 0\n",
    "  val_total_preds = 0\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader):\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_running_loss += loss.item()\n",
    "\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      val_total_preds += labels.size(0)\n",
    "      val_correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "  avg_val_loss = val_running_loss / len(val_loader)\n",
    "  val_losses.append(avg_val_loss)\n",
    "  val_accuracy = val_correct_preds / val_total_preds\n",
    "  val_accuracies.append(val_accuracy)\n",
    "\n",
    "  print(f\"Val Loss: {avg_val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
    "# After training, you can evaluate the final accuracy on the validation set\n",
    "print(f\"Final Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
